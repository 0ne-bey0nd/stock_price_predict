{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:45:47.867493Z",
     "start_time": "2024-06-17T09:45:45.254419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= init phase =========================\n",
    "import os\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.utils.data as data\n",
    "from Ashare import *\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"torch version: {torch.__version__} device: {device}\")\n",
    "project_dir = pathlib.Path('.').absolute()\n",
    "\n",
    "models_dir = os.path.join(project_dir, 'models')\n",
    "images_dir = os.path.join(project_dir, 'images')\n",
    "\n",
    "\n",
    "def make_sure_dir_exists(dir):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "\n",
    "make_sure_dir_exists(models_dir)\n",
    "make_sure_dir_exists(images_dir)\n",
    "LSTM_bin_classification_model_dir = os.path.join(models_dir, 'LSTM_bin_classification1')\n",
    "\n",
    "print(f\"model_dir: {models_dir}\")\n",
    "print(f\"images_dir: {images_dir}\")"
   ],
   "id": "68aa4c899ebbd0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.3.0+cu121 device: cuda\n",
      "model_dir: D:\\college\\NLP\\stock_price_predict\\models\n",
      "images_dir: D:\\college\\NLP\\stock_price_predict\\images\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:45:51.838716Z",
     "start_time": "2024-06-17T09:45:51.824717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= data phase =========================\n",
    "\n",
    "def produce_data(stock_code: str, day_nums: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get raw data from internet or somewhere, just get , not handle the data\n",
    "    :param stock_code:\n",
    "    :param day_nums:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return get_price(stock_code, frequency='1d', count=day_nums)\n",
    "\n",
    "\n",
    "def process_data(stock_code: str, day_nums: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    handle the raw data, not for the train phase\n",
    "    :param stock_code:\n",
    "    :param day_nums:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = produce_data(stock_code, day_nums)\n",
    "\n",
    "    # drop null sample\n",
    "    data = data.dropna()\n",
    "    # drop the rows containing the 0\n",
    "    data = data[~(data == 0).any(axis=1)]\n",
    "\n",
    "    # get data\n",
    "    # print(data.shape)\n",
    "\n",
    "    # we define the problem that we predict close price of a day use the previous days_seq_len day's data\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(stock_code: str, day_nums: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    the interface to get the preliminary data\n",
    "    :param stock_code:\n",
    "    :param day_nums:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return process_data(stock_code, day_nums)\n"
   ],
   "id": "3f09fcc6e76186c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:45:52.672849Z",
     "start_time": "2024-06-17T09:45:52.569852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= model phase =========================\n",
    "# define the model\n",
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, out_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, out_dim)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_model(model_name: str, *args, **kwargs) -> nn.Module:\n",
    "    model_name = model_name.lower()\n",
    "    if model_name == 'lstm':\n",
    "        model = LSTM(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"model_name: {model_name} is not supported\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def data_set_label(data: pd.DataFrame, pred_day_num: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    sample the data\n",
    "    return the dataset to train the model\n",
    "    :param data:\n",
    "    :param pred_day_num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_with_label = data.copy()\n",
    "    # let's get the label first\n",
    "    # label is binary, if the close price rises, the value is 1, otherwise, the value is 0\n",
    "    data_with_label.loc[:, 'next_close'] = data_with_label['close'].shift(-pred_day_num)\n",
    "    # drop the last sample\n",
    "    # data_with_label = data_with_label.dropna()\n",
    "\n",
    "    data_with_label.loc[:, 'label'] = (data_with_label['next_close'] - data_with_label['close']).apply(\n",
    "        lambda x: 1 if x > 0 else 0)\n",
    "    data_with_label = data_with_label.drop('next_close', axis=1)\n",
    "    return data_with_label\n",
    "\n",
    "\n",
    "def data_sequence_modeling(data: pd.DataFrame, days_seq_len: int) -> tuple[ndarray, Any, Any]:\n",
    "    \"\"\"\n",
    "    data sequence modeling\n",
    "    :param days_seq_len:\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    label = data.loc[:, 'label'][days_seq_len:].values\n",
    "    label = label.reshape(-1, 1)\n",
    "    unprocessed_features = data.drop(['label'], axis=1)\n",
    "\n",
    "    # so let's go on to deal with the data, remember we need our data to become dataset!\n",
    "    # we already know that our feature is not a matrix like before, it is a 3-D tensor in shape of (sample_size, sequence_len, feature_dim)\n",
    "    sample_size = label.shape[0]\n",
    "    # print(sample_size, sequence_len, feature_dim)\n",
    "\n",
    "    # we need to prepare for the features of every sample\n",
    "    features = []\n",
    "    for sample_idx in range(0, sample_size):\n",
    "        sample_features = []\n",
    "        for day_idx in range(days_seq_len):\n",
    "            sample_features.append(unprocessed_features.iloc[sample_idx + day_idx, :])\n",
    "        features.append(sample_features)\n",
    "    features = np.array(features)\n",
    "    time_seq = data.index[days_seq_len:]\n",
    "\n",
    "    return features, label, time_seq\n",
    "\n",
    "\n",
    "def data_split_and_preprocessing(features: ndarray, label: ndarray, test_data_ratio: float) -> tuple[Any, Any]:\n",
    "    \"\"\"\n",
    "    data split and preprocessing\n",
    "    :param test_data_ratio:\n",
    "    :param features:\n",
    "    :param label:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(torch.from_numpy(features).float(), torch.from_numpy(label).float())\n",
    "\n",
    "    # get train data and test data\n",
    "    from torch.utils.data import random_split\n",
    "    train_data_size = int((1 - test_data_ratio) * len(dataset))\n",
    "    test_data_size = len(dataset) - train_data_size\n",
    "    train_data, test_data = torch.utils.data.random_split(dataset, [train_data_size, test_data_size])\n",
    "\n",
    "    # data preprocessing, only normalize the features, not the labelprint(train_data)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    train_features = train_data.dataset.tensors[0]\n",
    "    test_features = test_data.dataset.tensors[0]\n",
    "\n",
    "    sequence_len = days_seq_len\n",
    "    feature_dim = train_features.shape[2]\n",
    "\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, feature_dim)).reshape(-1, sequence_len,\n",
    "                                                                                           feature_dim)\n",
    "    test_features = scaler.transform(test_features.reshape(-1, feature_dim)).reshape(-1, sequence_len, feature_dim)\n",
    "\n",
    "    train_data = TensorDataset(torch.from_numpy(train_features).float(), train_data.dataset.tensors[1])\n",
    "    test_data = TensorDataset(torch.from_numpy(test_features).float(), test_data.dataset.tensors[1])\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def dataset_prepare(raw_data: pd.DataFrame,pred_day_num:int ,days_seq_len: int, test_data_ratio: float) -> tuple[Any, Any, Any]:\n",
    "    \"\"\"\n",
    "    get the train dataset and test dataset and the time sequence\n",
    "    :param pred_day_num: \n",
    "    :param test_data_ratio:\n",
    "    :param raw_data:\n",
    "    :param days_seq_len:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_with_label = data_set_label(raw_data, pred_day_num)\n",
    "    features, label, time_seq = data_sequence_modeling(data_with_label, days_seq_len)\n",
    "    train_dataset, test_dataset = data_split_and_preprocessing(features, label, test_data_ratio)\n",
    "    return train_dataset, test_dataset, time_seq\n",
    "\n",
    "\n",
    "# save the model\n",
    "def save_model(model: torch.nn.Module, model_dir: str, model_acc: float):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_name = 'LSTM_bin_classification.pth'\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    # delete the previous model\n",
    "    if os.path.exists(model_path):\n",
    "        os.remove(model_path)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    # save the accuracy\n",
    "    with open(os.path.join(model_dir, 'accuracy.txt'), 'w') as f:\n",
    "        f.write(str(model_acc))\n",
    "\n",
    "    print('Model saved at {}'.format(model_path), 'Accuracy:', model_acc)\n",
    "\n",
    "\n",
    "def train(model: nn.Module, train_loader: data.DataLoader, test_loader: data.DataLoader, criterion: nn.Module,\n",
    "          num_epochs: int, optimizer: optim.Optimizer) -> tuple[\n",
    "    nn.Module, list[float], list[float], list[float], list[float]]:\n",
    "    # train the model\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy_list = []\n",
    "    test_accuracy_list = []\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0\n",
    "        train_accuracy = 0\n",
    "        for features, labels in train_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss_sum += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            # print(predicted.shape, labels.shape)\n",
    "            train_accuracy += (predicted == labels).sum()\n",
    "            train_accuracy = train_accuracy.item()\n",
    "        # print(train_accuracy)\n",
    "        # print(train_accuracy/len(train_data))\n",
    "        train_loss.append(train_loss_sum / len(train_loader))\n",
    "        train_accuracy_list.append(train_accuracy / len(train_loader.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        test_loss_sum = 0\n",
    "        test_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_loader:\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss_sum += loss.item()\n",
    "\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                test_accuracy += (predicted == labels).sum()\n",
    "                test_accuracy = test_accuracy.item()\n",
    "        test_loss.append(test_loss_sum / len(test_loader))\n",
    "        test_accuracy_list.append(test_accuracy / len(test_loader.dataset))\n",
    "        if test_accuracy_list[-1] > best_accuracy:\n",
    "            best_accuracy = test_accuracy_list[-1]\n",
    "            best_model = model\n",
    "            # save the model\n",
    "            save_model(model, LSTM_bin_classification_model_dir, best_accuracy)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\n",
    "                'Epoch [{}/{}], Train Loss: {:.8f}, Test Loss: {:.8f}, Train Accuracy: {:.4f}, Test Accuracy: {:.4f}'.format(\n",
    "                    epoch + 1, num_epochs, train_loss[-1], test_loss[-1], train_accuracy_list[-1],\n",
    "                    test_accuracy_list[-1]))\n",
    "\n",
    "    return best_model, train_loss, test_loss, train_accuracy_list, test_accuracy_list"
   ],
   "id": "ae64a57726c22902",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:45:53.522017Z",
     "start_time": "2024-06-17T09:45:53.514017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= utils =========================\n",
    "def line_chart(data_list: list, label_list: list, title: str = None, xlabel: str = None, ylabel: str = None):\n",
    "    assert len(data_list) == len(label_list)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    for idx, data in enumerate(data_list):\n",
    "        plt.plot(data, label=label_list[idx])\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()"
   ],
   "id": "1b9d91ad64d92baf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:45:54.846648Z",
     "start_time": "2024-06-17T09:45:54.192251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= run =========================\n",
    "# ========================= data phase =========================\n",
    "stock_code = 'sz399300'\n",
    "day_nums = 10000\n",
    "raw_data = get_data(stock_code, day_nums)\n",
    "raw_data.shape"
   ],
   "id": "4c9c54f0bd1bd123",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4722, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:46:07.973909Z",
     "start_time": "2024-06-17T09:46:05.453977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= model phase =========================\n",
    "\n",
    "days_seq_len = 7\n",
    "test_data_ratio = 0.3\n",
    "pred_day_num = 3\n",
    "train_dataset, test_dataset, time_seq = dataset_prepare(raw_data,pred_day_num ,days_seq_len, test_data_ratio)\n",
    "sample_size, sequence_len, feature_dim = train_dataset.tensors[0].shape\n",
    "print(f\"sample_size: {sample_size}, sequence_len: {sequence_len}, feature_dim: {feature_dim}\")\n"
   ],
   "id": "fa902c262f095349",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size: 4715, sequence_len: 7, feature_dim: 5\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:46:13.671528Z",
     "start_time": "2024-06-17T09:46:09.949623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dim = feature_dim\n",
    "hidden_dim = 16\n",
    "num_layers = 2\n",
    "out_dim = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 500\n",
    "\n",
    "# prepare the data loader\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = LSTM(input_dim, hidden_dim, num_layers, out_dim).to(device)\n",
    "print(model)"
   ],
   "id": "6ff773dcb319daf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(5, 16, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:51:28.029287Z",
     "start_time": "2024-06-17T09:46:14.245100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the loss function and the optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# train the model\n",
    "best_model, train_loss, test_loss, train_accuracy_list, test_accuracy_list = train(model, train_loader, test_loader,\n",
    "                                                                                   criterion,\n",
    "                                                                                   num_epochs,optimizer)\n"
   ],
   "id": "2a63871970a5378d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.528525980911983\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5376458112407211\n",
      "Epoch [10/500], Train Loss: 0.69049990, Test Loss: 0.68859018, Train Accuracy: 0.5283, Test Accuracy: 0.5372\n",
      "Epoch [20/500], Train Loss: 0.68896885, Test Loss: 0.68925179, Train Accuracy: 0.5313, Test Accuracy: 0.5285\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5414634146341464\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5461293743372216\n",
      "Epoch [30/500], Train Loss: 0.68628288, Test Loss: 0.68451702, Train Accuracy: 0.5306, Test Accuracy: 0.5461\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5469777306468717\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5471898197242842\n",
      "Epoch [40/500], Train Loss: 0.68369968, Test Loss: 0.67982505, Train Accuracy: 0.5385, Test Accuracy: 0.5472\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5537645811240721\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5575821845174973\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5605514316012725\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5626723223753977\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5637327677624603\n",
      "Epoch [50/500], Train Loss: 0.67919628, Test Loss: 0.67263238, Train Accuracy: 0.5495, Test Accuracy: 0.5637\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5700954400848356\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5724284199363733\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5728525980911983\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5800636267232238\n",
      "Epoch [60/500], Train Loss: 0.66744907, Test Loss: 0.66373286, Train Accuracy: 0.5805, Test Accuracy: 0.5782\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.584305408271474\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5855779427359491\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5951219512195122\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.5959703075291622\n",
      "Epoch [70/500], Train Loss: 0.65706544, Test Loss: 0.65431355, Train Accuracy: 0.5839, Test Accuracy: 0.5832\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6040296924708377\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6074231177094379\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6116648992576882\n",
      "Epoch [80/500], Train Loss: 0.64272279, Test Loss: 0.63418939, Train Accuracy: 0.5953, Test Accuracy: 0.6117\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.616542948038176\n",
      "Epoch [90/500], Train Loss: 0.64860766, Test Loss: 0.63875267, Train Accuracy: 0.5934, Test Accuracy: 0.6087\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6186638388123011\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6290562036055143\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6335100742311771\n",
      "Epoch [100/500], Train Loss: 0.63624960, Test Loss: 0.61709977, Train Accuracy: 0.6025, Test Accuracy: 0.6216\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6356309650053023\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6381760339342524\n",
      "Epoch [110/500], Train Loss: 0.63639094, Test Loss: 0.61771430, Train Accuracy: 0.6100, Test Accuracy: 0.6267\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6388123011664899\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6422057264050901\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6445387062566278\n",
      "Epoch [120/500], Train Loss: 0.59836784, Test Loss: 0.58965413, Train Accuracy: 0.6348, Test Accuracy: 0.6420\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6481442205726405\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6532343584305408\n",
      "Epoch [130/500], Train Loss: 0.60480821, Test Loss: 0.59201205, Train Accuracy: 0.6206, Test Accuracy: 0.6484\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6534464475079533\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6579003181336162\n",
      "Epoch [140/500], Train Loss: 0.58559729, Test Loss: 0.58356988, Train Accuracy: 0.6486, Test Accuracy: 0.6488\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6685047720042417\n",
      "Epoch [150/500], Train Loss: 0.58189757, Test Loss: 0.56628563, Train Accuracy: 0.6405, Test Accuracy: 0.6571\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6708377518557794\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6729586426299046\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6755037115588547\n",
      "Epoch [160/500], Train Loss: 0.61133172, Test Loss: 0.59671773, Train Accuracy: 0.6348, Test Accuracy: 0.6456\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6788971367974549\n",
      "Epoch [170/500], Train Loss: 0.55884629, Test Loss: 0.54303684, Train Accuracy: 0.6641, Test Accuracy: 0.6789\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6839872746553552\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6850477200424178\n",
      "Epoch [180/500], Train Loss: 0.55800267, Test Loss: 0.59951044, Train Accuracy: 0.6674, Test Accuracy: 0.6526\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.688016967126193\n",
      "Epoch [190/500], Train Loss: 0.53783351, Test Loss: 0.52624551, Train Accuracy: 0.6751, Test Accuracy: 0.6880\n",
      "Epoch [200/500], Train Loss: 0.59584638, Test Loss: 0.56379268, Train Accuracy: 0.6386, Test Accuracy: 0.6607\n",
      "Epoch [210/500], Train Loss: 0.54569868, Test Loss: 0.55145003, Train Accuracy: 0.6687, Test Accuracy: 0.6685\n",
      "Epoch [220/500], Train Loss: 0.56723727, Test Loss: 0.56215765, Train Accuracy: 0.6585, Test Accuracy: 0.6662\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6956521739130435\n",
      "Epoch [230/500], Train Loss: 0.59164932, Test Loss: 0.56537412, Train Accuracy: 0.6437, Test Accuracy: 0.6655\n",
      "Epoch [240/500], Train Loss: 0.57976151, Test Loss: 0.57847104, Train Accuracy: 0.6560, Test Accuracy: 0.6617\n",
      "Epoch [250/500], Train Loss: 0.56511458, Test Loss: 0.56883715, Train Accuracy: 0.6710, Test Accuracy: 0.6636\n",
      "Epoch [260/500], Train Loss: 0.58699741, Test Loss: 0.57316725, Train Accuracy: 0.6458, Test Accuracy: 0.6556\n",
      "Epoch [270/500], Train Loss: 0.53891106, Test Loss: 0.52075639, Train Accuracy: 0.6793, Test Accuracy: 0.6940\n",
      "Epoch [280/500], Train Loss: 0.55197203, Test Loss: 0.54789018, Train Accuracy: 0.6687, Test Accuracy: 0.6766\n",
      "Epoch [290/500], Train Loss: 0.55588209, Test Loss: 0.53074104, Train Accuracy: 0.6723, Test Accuracy: 0.6865\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6967126193001061\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.6971367974549311\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7066808059384941\n",
      "Epoch [300/500], Train Loss: 0.53326978, Test Loss: 0.50634539, Train Accuracy: 0.6817, Test Accuracy: 0.7067\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7071049840933192\n",
      "Epoch [310/500], Train Loss: 0.54994888, Test Loss: 0.52736253, Train Accuracy: 0.6757, Test Accuracy: 0.6933\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7073170731707317\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7092258748674444\n",
      "Epoch [320/500], Train Loss: 0.53174021, Test Loss: 0.51210695, Train Accuracy: 0.6903, Test Accuracy: 0.6995\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7100742311770943\n",
      "Epoch [330/500], Train Loss: 0.53526284, Test Loss: 0.52031493, Train Accuracy: 0.6846, Test Accuracy: 0.6982\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7151643690349947\n",
      "Epoch [340/500], Train Loss: 0.63777480, Test Loss: 0.59867507, Train Accuracy: 0.6310, Test Accuracy: 0.6488\n",
      "Epoch [350/500], Train Loss: 0.55590948, Test Loss: 0.54143704, Train Accuracy: 0.6774, Test Accuracy: 0.6870\n",
      "Epoch [360/500], Train Loss: 0.54613412, Test Loss: 0.53545336, Train Accuracy: 0.6823, Test Accuracy: 0.6988\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7158006362672322\n",
      "Epoch [370/500], Train Loss: 0.52482906, Test Loss: 0.49393058, Train Accuracy: 0.6984, Test Accuracy: 0.7158\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7172852598091198\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7200424178154825\n",
      "Epoch [380/500], Train Loss: 0.51256018, Test Loss: 0.50389757, Train Accuracy: 0.7113, Test Accuracy: 0.7177\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7247083775185578\n",
      "Epoch [390/500], Train Loss: 0.54338382, Test Loss: 0.52116092, Train Accuracy: 0.6929, Test Accuracy: 0.7014\n",
      "Epoch [400/500], Train Loss: 0.51466343, Test Loss: 0.50196541, Train Accuracy: 0.6995, Test Accuracy: 0.7130\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7259809119830328\n",
      "Epoch [410/500], Train Loss: 0.51561186, Test Loss: 0.51639466, Train Accuracy: 0.6995, Test Accuracy: 0.7073\n",
      "Epoch [420/500], Train Loss: 0.53807696, Test Loss: 0.53482126, Train Accuracy: 0.6940, Test Accuracy: 0.7035\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7266171792152704\n",
      "Epoch [430/500], Train Loss: 0.52563457, Test Loss: 0.50087493, Train Accuracy: 0.7010, Test Accuracy: 0.7133\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7268292682926829\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.728101802757158\n",
      "Epoch [440/500], Train Loss: 0.50943762, Test Loss: 0.48842337, Train Accuracy: 0.7073, Test Accuracy: 0.7275\n",
      "Epoch [450/500], Train Loss: 0.51079406, Test Loss: 0.51601880, Train Accuracy: 0.7099, Test Accuracy: 0.7058\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7331919406150583\n",
      "Epoch [460/500], Train Loss: 0.49406353, Test Loss: 0.46884004, Train Accuracy: 0.7135, Test Accuracy: 0.7294\n",
      "Epoch [470/500], Train Loss: 0.52251739, Test Loss: 0.48800865, Train Accuracy: 0.6961, Test Accuracy: 0.7160\n",
      "Epoch [480/500], Train Loss: 0.52580110, Test Loss: 0.52183348, Train Accuracy: 0.7035, Test Accuracy: 0.7010\n",
      "Epoch [490/500], Train Loss: 0.52204446, Test Loss: 0.56430431, Train Accuracy: 0.7035, Test Accuracy: 0.6831\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7384941675503711\n",
      "Model saved at D:\\college\\NLP\\stock_price_predict\\models\\LSTM_bin_classification1\\LSTM_bin_classification.pth Accuracy: 0.7452810180275716\n",
      "Epoch [500/500], Train Loss: 0.48008133, Test Loss: 0.48683776, Train Accuracy: 0.7306, Test Accuracy: 0.7253\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "line_chart([train_loss, test_loss], ['train_loss', 'test_loss'], '')\n",
    "plt.savefig(os.path.join(images_dir, 'loss.png'))\n",
    "\n",
    "line_chart([train_accuracy_list, test_accuracy_list], ['train_accuracy', 'test_accuracy'], '')\n",
    "plt.savefig(os.path.join(images_dir, 'accuracy.png'))\n"
   ],
   "id": "18868930ccbe77cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9456c6b53aca1ae",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
