{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:36.649913Z",
     "start_time": "2024-06-17T12:15:34.239607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= init phase =========================\n",
    "import os\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.utils.data as data\n",
    "from Ashare import *\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"torch version: {torch.__version__} device: {device}\")\n",
    "project_dir = pathlib.Path('.').absolute()\n",
    "\n",
    "models_dir = os.path.join(project_dir, 'models')\n",
    "images_dir = os.path.join(project_dir, 'images')\n",
    "\n",
    "\n",
    "def make_sure_dir_exists(dir):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "\n",
    "make_sure_dir_exists(models_dir)\n",
    "make_sure_dir_exists(images_dir)\n",
    "LSTM_bin_classification_model_dir = os.path.join(models_dir, 'LSTM_bin_classification')\n",
    "\n",
    "print(f\"model_dir: {models_dir}\")\n",
    "print(f\"images_dir: {images_dir}\")"
   ],
   "id": "68aa4c899ebbd0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.3.0+cu121 device: cuda\n",
      "model_dir: D:\\college\\NLP\\stock_price_predict\\models\n",
      "images_dir: D:\\college\\NLP\\stock_price_predict\\images\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:36.664932Z",
     "start_time": "2024-06-17T12:15:36.651913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= data phase =========================\n",
    "\n",
    "def produce_data(stock_code: str, day_nums: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get raw data from internet or somewhere, just get , not handle the data\n",
    "    :param stock_code:\n",
    "    :param day_nums:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return get_price(stock_code, frequency='1d', count=day_nums)\n",
    "\n",
    "\n",
    "def process_data(stock_code: str, day_nums: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    handle the raw data, not for the train phase\n",
    "    :param stock_code:\n",
    "    :param day_nums:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = produce_data(stock_code, day_nums)\n",
    "\n",
    "    # drop null sample\n",
    "    data = data.dropna()\n",
    "    # drop the rows containing the 0\n",
    "    data = data[~(data == 0).any(axis=1)]\n",
    "\n",
    "    # get data\n",
    "    # print(data.shape)\n",
    "\n",
    "    # we define the problem that we predict close price of a day use the previous days_seq_len day's data\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data(stock_code: str, day_nums: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    the interface to get the preliminary data\n",
    "    :param stock_code:\n",
    "    :param day_nums:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return process_data(stock_code, day_nums)\n"
   ],
   "id": "3f09fcc6e76186c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:36.696676Z",
     "start_time": "2024-06-17T12:15:36.666885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= model phase =========================\n",
    "# define the model\n",
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, out_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, out_dim)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_model(model_name: str, *args, **kwargs) -> nn.Module:\n",
    "    model_name = model_name.lower()\n",
    "    if model_name == 'lstm':\n",
    "        model = LSTM(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"model_name: {model_name} is not supported\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def data_set_label(data: pd.DataFrame, days_seq_len: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    sample the data\n",
    "    return the dataset to train the model\n",
    "    :param data:\n",
    "    :param days_seq_len:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_with_label = data.copy()\n",
    "    # let's get the label first\n",
    "    # label is binary, if the close price rises, the value is 1, otherwise, the value is 0\n",
    "    data_with_label.loc[:, 'next_close'] = data_with_label['close'].shift(-days_seq_len)\n",
    "    # drop the last sample\n",
    "    # data_with_label = data_with_label.dropna()\n",
    "\n",
    "    data_with_label.loc[:, 'label'] = (data_with_label['next_close'] - data_with_label['close']).apply(\n",
    "        lambda x: 1 if x > 0 else 0)\n",
    "    data_with_label = data_with_label.drop('next_close', axis=1)\n",
    "    return data_with_label\n",
    "\n",
    "\n",
    "def data_sequence_modeling(data: pd.DataFrame, days_seq_len: int) -> tuple[ndarray, Any, Any]:\n",
    "    \"\"\"\n",
    "    data sequence modeling\n",
    "    :param days_seq_len:\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    label = data.loc[:, 'label'][days_seq_len:].values\n",
    "    label = label.reshape(-1, 1)\n",
    "    unprocessed_features = data.drop(['label'], axis=1)\n",
    "\n",
    "    # so let's go on to deal with the data, remember we need our data to become dataset!\n",
    "    # we already know that our feature is not a matrix like before, it is a 3-D tensor in shape of (sample_size, sequence_len, feature_dim)\n",
    "    sample_size = label.shape[0]\n",
    "    # print(sample_size, sequence_len, feature_dim)\n",
    "\n",
    "    # we need to prepare for the features of every sample\n",
    "    features = []\n",
    "    for sample_idx in range(0, sample_size):\n",
    "        sample_features = []\n",
    "        for day_idx in range(days_seq_len):\n",
    "            sample_features.append(unprocessed_features.iloc[sample_idx + day_idx, :])\n",
    "        features.append(sample_features)\n",
    "    features = np.array(features)\n",
    "    time_seq = data.index[days_seq_len:]\n",
    "\n",
    "    return features, label, time_seq\n",
    "\n",
    "\n",
    "def data_split_and_preprocessing(features: ndarray, label: ndarray, test_data_ratio: float) -> tuple[Any, Any]:\n",
    "    \"\"\"\n",
    "    data split and preprocessing\n",
    "    :param test_data_ratio:\n",
    "    :param features:\n",
    "    :param label:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(torch.from_numpy(features).float(), torch.from_numpy(label).float())\n",
    "\n",
    "    # get train data and test data\n",
    "    from torch.utils.data import random_split\n",
    "    train_data_size = int((1 - test_data_ratio) * len(dataset))\n",
    "    test_data_size = len(dataset) - train_data_size\n",
    "    train_data, test_data = torch.utils.data.random_split(dataset, [train_data_size, test_data_size])\n",
    "\n",
    "    # data preprocessing, only normalize the features, not the labelprint(train_data)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    train_features = train_data.dataset.tensors[0]\n",
    "    test_features = test_data.dataset.tensors[0]\n",
    "\n",
    "    sequence_len = days_seq_len\n",
    "    feature_dim = train_features.shape[2]\n",
    "\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, feature_dim)).reshape(-1, sequence_len,\n",
    "                                                                                           feature_dim)\n",
    "    test_features = scaler.transform(test_features.reshape(-1, feature_dim)).reshape(-1, sequence_len, feature_dim)\n",
    "\n",
    "    train_data = TensorDataset(torch.from_numpy(train_features).float(), train_data.dataset.tensors[1])\n",
    "    test_data = TensorDataset(torch.from_numpy(test_features).float(), test_data.dataset.tensors[1])\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def dataset_prepare(raw_data: pd.DataFrame, days_seq_len: int, test_data_ratio: float) -> tuple[Any, Any, Any]:\n",
    "    \"\"\"\n",
    "    get the train dataset and test dataset and the time sequence\n",
    "    :param test_data_ratio:\n",
    "    :param raw_data:\n",
    "    :param days_seq_len:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_with_label = data_set_label(raw_data, days_seq_len)\n",
    "    features, label, time_seq = data_sequence_modeling(data_with_label, days_seq_len)\n",
    "    train_dataset, test_dataset = data_split_and_preprocessing(features, label, test_data_ratio)\n",
    "    return train_dataset, test_dataset, time_seq\n",
    "\n",
    "\n",
    "# save the model\n",
    "def save_model(model: torch.nn.Module, model_dir: str, model_acc: float):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_name = 'LSTM_bin_classification.pth'\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    # delete the previous model\n",
    "    if os.path.exists(model_path):\n",
    "        os.remove(model_path)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    # save the accuracy\n",
    "    with open(os.path.join(model_dir, 'accuracy.txt'), 'w') as f:\n",
    "        f.write(str(model_acc))\n",
    "\n",
    "    print('Model saved at {}'.format(model_path), 'Accuracy:', model_acc)\n",
    "\n",
    "\n",
    "def train(model: nn.Module, train_loader: data.DataLoader, test_loader: data.DataLoader, criterion: nn.Module,\n",
    "          num_epochs: int, optimizer: optim.Optimizer) -> tuple[\n",
    "    nn.Module, list[float], list[float], list[float], list[float]]:\n",
    "    # train the model\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy_list = []\n",
    "    test_accuracy_list = []\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0\n",
    "        train_accuracy = 0\n",
    "        for features, labels in train_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss_sum += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            # print(predicted.shape, labels.shape)\n",
    "            train_accuracy += (predicted == labels).sum()\n",
    "            train_accuracy = train_accuracy.item()\n",
    "        # print(train_accuracy)\n",
    "        # print(train_accuracy/len(train_data))\n",
    "        train_loss.append(train_loss_sum / len(train_loader))\n",
    "        train_accuracy_list.append(train_accuracy / len(train_loader.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        test_loss_sum = 0\n",
    "        test_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_loader:\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss_sum += loss.item()\n",
    "\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                test_accuracy += (predicted == labels).sum()\n",
    "                test_accuracy = test_accuracy.item()\n",
    "        test_loss.append(test_loss_sum / len(test_loader))\n",
    "        test_accuracy_list.append(test_accuracy / len(test_loader.dataset))\n",
    "        if test_accuracy_list[-1] > best_accuracy:\n",
    "            best_accuracy = test_accuracy_list[-1]\n",
    "            best_model = model\n",
    "            # save the model\n",
    "            save_model(model, LSTM_bin_classification_model_dir, best_accuracy)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\n",
    "                'Epoch [{}/{}], Train Loss: {:.8f}, Test Loss: {:.8f}, Train Accuracy: {:.4f}, Test Accuracy: {:.4f}'.format(\n",
    "                    epoch + 1, num_epochs, train_loss[-1], test_loss[-1], train_accuracy_list[-1],\n",
    "                    test_accuracy_list[-1]))\n",
    "\n",
    "    return best_model, train_loss, test_loss, train_accuracy_list, test_accuracy_list"
   ],
   "id": "ae64a57726c22902",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:37.372729Z",
     "start_time": "2024-06-17T12:15:37.361729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= utils =========================\n",
    "def line_chart(data_list: list, label_list: list, title: str = None, xlabel: str = None, ylabel: str = None):\n",
    "    assert len(data_list) == len(label_list)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    for idx, data in enumerate(data_list):\n",
    "        plt.plot(data, label=label_list[idx])\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()"
   ],
   "id": "1b9d91ad64d92baf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:37.781702Z",
     "start_time": "2024-06-17T12:15:37.770701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(model_path: str) -> nn.Module:\n",
    "    return torch.load(model_path)\n"
   ],
   "id": "657a5e3f8097d29d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:40.753436Z",
     "start_time": "2024-06-17T12:15:40.106950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= run =========================\n",
    "# ========================= data phase =========================\n",
    "stock_code = 'sz399300'\n",
    "day_nums = 10000\n",
    "raw_data = get_data(stock_code, day_nums)"
   ],
   "id": "4c9c54f0bd1bd123",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:43.852634Z",
     "start_time": "2024-06-17T12:15:41.140369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================= model phase =========================\n",
    "\n",
    "days_seq_len = 7\n",
    "test_data_ratio = 0.3\n",
    "train_dataset, test_dataset, time_seq = dataset_prepare(raw_data, days_seq_len, test_data_ratio)\n",
    "sample_size, sequence_len, feature_dim = train_dataset.tensors[0].shape\n",
    "print(f\"sample_size: {sample_size}, sequence_len: {sequence_len}, feature_dim: {feature_dim}\")\n"
   ],
   "id": "fa902c262f095349",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size: 4715, sequence_len: 7, feature_dim: 5\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:49.515360Z",
     "start_time": "2024-06-17T12:15:46.197125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dim = feature_dim\n",
    "hidden_dim = 16\n",
    "num_layers = 2\n",
    "out_dim = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 500\n",
    "\n",
    "# prepare the data loader\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = LSTM(input_dim, hidden_dim, num_layers, out_dim).to(device)\n",
    "# load the trained model\n",
    "model.load_state_dict(load_model(os.path.join(LSTM_bin_classification_model_dir, 'LSTM_bin_classification.pth')))\n",
    "print(model)\n"
   ],
   "id": "6ff773dcb319daf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(5, 16, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:15:50.426513Z",
     "start_time": "2024-06-17T12:15:50.151937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use the trained model\n",
    "model.eval()\n",
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "\n",
    "        acc += (predicted == labels).sum()\n",
    "\n",
    "    acc = acc.item() / len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test Accuracy: {acc}\")"
   ],
   "id": "ff6df2cdbbfee5a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5658536585365853\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:18:03.564649Z",
     "start_time": "2024-06-17T12:18:03.525602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_batch(test_features, test_labels):\n",
    "    \"\"\"\n",
    "    :param test_features:\n",
    "    :param test_labels:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert type(test_features) == type(test_labels)\n",
    "    if type(test_features) == np.ndarray:\n",
    "        test_features = torch.from_numpy(test_features).float()\n",
    "        test_labels = torch.tensor(test_labels).float()\n",
    "    elif type(test_features) == torch.Tensor:\n",
    "        ...        \n",
    "    else:\n",
    "        raise ValueError\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        test_features = test_features.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "\n",
    "        outputs = model(test_features)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "\n",
    "        acc += (predicted == test_labels).sum()\n",
    "\n",
    "    acc = acc.item() / len(test_labels)\n",
    "    return predicted, acc\n",
    "\n",
    "def test_day_section(begin_idx, end_idx=None):\n",
    "    if end_idx == None:\n",
    "        end_idx = len(raw_data)\n",
    "    test_data = raw_data[begin_idx:end_idx]\n",
    "    test_data = data_set_label(test_data, days_seq_len)\n",
    "    print(test_data.shape)\n",
    "    test_features, test_labels, test_time_seq = data_sequence_modeling(test_data, days_seq_len)\n",
    "    print(test_features.shape, test_labels.shape, test_time_seq.shape)\n",
    "    predicted, acc = validate_batch(test_features, test_labels)\n",
    "    print(f\"Test Accuracy: {acc}\")\n",
    "\n",
    "test_day_section(-40)"
   ],
   "id": "9456c6b53aca1ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 6)\n",
      "(33, 7, 5) (33, 1) (33,)\n",
      "Test Accuracy: 0.7575757575757576\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:25:55.240584Z",
     "start_time": "2024-06-17T12:25:55.220576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(features) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    predict\n",
    "    :param features: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if type(features) == np.ndarray:\n",
    "        features = torch.from_numpy(features).float()\n",
    "    elif type(features) == torch.Tensor:\n",
    "        ...        \n",
    "    else:\n",
    "        raise ValueError\n",
    "    with torch.no_grad():\n",
    "        test_features = features.to(device)\n",
    "        outputs = model(test_features)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "    \n",
    "    result = predicted.cpu().numpy()\n",
    "    return result\n",
    "    \n",
    "\n",
    "test_data = raw_data[-7:]\n",
    "print(test_data.shape)\n",
    "features = torch.from_numpy(test_data.values).unsqueeze(0)\n",
    "print(features.shape)\n",
    "features"
   ],
   "id": "34adc32b4a626422",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5)\n",
      "torch.Size([1, 7, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[3.6022e+03, 3.6250e+03, 3.5842e+03, 3.5922e+03, 1.3789e+10],\n",
       "         [3.5946e+03, 3.6031e+03, 3.5521e+03, 3.5741e+03, 1.3110e+10],\n",
       "         [3.5558e+03, 3.5653e+03, 3.5259e+03, 3.5429e+03, 1.3452e+10],\n",
       "         [3.5391e+03, 3.5512e+03, 3.5316e+03, 3.5441e+03, 1.2281e+10],\n",
       "         [3.5482e+03, 3.5511e+03, 3.5202e+03, 3.5261e+03, 1.2325e+10],\n",
       "         [3.5148e+03, 3.5471e+03, 3.5035e+03, 3.5415e+03, 1.7152e+10],\n",
       "         [3.5214e+03, 3.5408e+03, 3.5207e+03, 3.5362e+03, 1.3743e+10]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted = predict(test_data)",
   "id": "4960dff544eafefc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:33:59.641337Z",
     "start_time": "2024-06-17T09:33:59.427113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for features, labels in test_loader:\n",
    "    predicted, acc = validate_batch(features, labels)\n",
    "    print(f\"Test Accuracy: {acc}\")"
   ],
   "id": "4fa533e92fb1ac1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.625\n",
      "Test Accuracy: 0.28125\n",
      "Test Accuracy: 0.28125\n",
      "Test Accuracy: 0.53125\n",
      "Test Accuracy: 0.6875\n",
      "Test Accuracy: 0.25\n",
      "Test Accuracy: 0.65625\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.71875\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.71875\n",
      "Test Accuracy: 0.53125\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 1.0\n",
      "Test Accuracy: 0.6875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 1.0\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.6875\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.65625\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.71875\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.65625\n",
      "Test Accuracy: 0.59375\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.6875\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.5\n",
      "Test Accuracy: 0.59375\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 1.0\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.71875\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 1.0\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.75\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.71875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.96875\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.6875\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.53125\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.59375\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.6875\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.6875\n",
      "Test Accuracy: 0.46875\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.875\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.8125\n",
      "Test Accuracy: 0.71875\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.71875\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.84375\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 0.9375\n",
      "Test Accuracy: 1.0\n",
      "Test Accuracy: 0.78125\n",
      "Test Accuracy: 0.90625\n",
      "Test Accuracy: 0.9090909090909091\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f7808a3a363ae2bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
